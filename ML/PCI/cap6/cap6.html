<!DOCTYPE HTML>
<html lang="en-US" >
    
    <head>
        
        <meta charset="UTF-8">
        <title>文档过滤 | 机器学习</title>
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="generator" content="GitBook 1.1.0">
        <meta name="HandheldFriendly" content="true"/>
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
        <meta name="apple-mobile-web-app-capable" content="yes">
        <meta name="apple-mobile-web-app-status-bar-style" content="black">
        <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
        <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">
        
    
    
    
    <link rel="next" href="../../PCI/cap7/cap7.html" />
    
    
    <link rel="prev" href="../../PCI/cap5/cap5.html" />
    

        
    </head>
    <body>
        
        
<link rel="stylesheet" href="../../gitbook/style.css">


        
    <div class="book" data-level="1.5" data-basepath="../.." data-revision="1428042646490">
    

<div class="book-summary">
    <div class="book-search">
        <input type="text" placeholder="Type to search" class="form-control" />
    </div>
    <ul class="summary">
        
    	
    	
    	

        

        
    
        
        <li class="chapter " data-level="0" data-path="index.html">
            
                
                    <a href="../../index.html">
                        <i class="fa fa-check"></i>
                        
                         Introduction
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="1" data-path="PCI/readme.html">
            
                
                    <a href="../../PCI/readme.html">
                        <i class="fa fa-check"></i>
                        
                            <b>1.</b>
                        
                         集体智慧编程
                    </a>
                
            
            
            <ul class="articles">
                
    
        
        <li class="chapter " data-level="1.1" data-path="PCI/cap2/cap2.html">
            
                
                    <a href="../../PCI/cap2/cap2.html">
                        <i class="fa fa-check"></i>
                        
                            <b>1.1.</b>
                        
                         提供推荐
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="1.2" data-path="PCI/cap3/cap3.html">
            
                
                    <a href="../../PCI/cap3/cap3.html">
                        <i class="fa fa-check"></i>
                        
                            <b>1.2.</b>
                        
                         发现群组
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="1.3" data-path="PCI/cap4/cap4.html">
            
                
                    <a href="../../PCI/cap4/cap4.html">
                        <i class="fa fa-check"></i>
                        
                            <b>1.3.</b>
                        
                         搜索与排名
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="1.4" data-path="PCI/cap5/cap5.html">
            
                
                    <a href="../../PCI/cap5/cap5.html">
                        <i class="fa fa-check"></i>
                        
                            <b>1.4.</b>
                        
                         优化
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter active" data-level="1.5" data-path="PCI/cap6/cap6.html">
            
                
                    <a href="../../PCI/cap6/cap6.html">
                        <i class="fa fa-check"></i>
                        
                            <b>1.5.</b>
                        
                         文档过滤
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="1.6" data-path="PCI/cap7/cap7.html">
            
                
                    <a href="../../PCI/cap7/cap7.html">
                        <i class="fa fa-check"></i>
                        
                            <b>1.6.</b>
                        
                         决策树建模
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="1.7" data-path="PCI/cap8/cap8.html">
            
                
                    <a href="../../PCI/cap8/cap8.html">
                        <i class="fa fa-check"></i>
                        
                            <b>1.7.</b>
                        
                         构建价格模型
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="1.8" data-path="PCI/cap9/cap9.html">
            
                
                    <a href="../../PCI/cap9/cap9.html">
                        <i class="fa fa-check"></i>
                        
                            <b>1.8.</b>
                        
                         高阶分类：核心方法和SVMs
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="1.9" data-path="PCI/cap10/cap10.html">
            
                
                    <a href="../../PCI/cap10/cap10.html">
                        <i class="fa fa-check"></i>
                        
                            <b>1.9.</b>
                        
                         寻找独立特征
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="1.10" data-path="PCI/cap11/cap11.html">
            
                
                    <a href="../../PCI/cap11/cap11.html">
                        <i class="fa fa-check"></i>
                        
                            <b>1.10.</b>
                        
                         智能进化
                    </a>
                
            
            
        </li>
    
        
        <li class="chapter " data-level="1.11" data-path="PCI/cap12/cap12.html">
            
                
                    <a href="../../PCI/cap12/cap12.html">
                        <i class="fa fa-check"></i>
                        
                            <b>1.11.</b>
                        
                         算法总结
                    </a>
                
            
            
        </li>
    

            </ul>
            
        </li>
    


        
        <li class="divider"></li>
        <li>
            <a href="http://www.gitbook.io/" target="blank" class="gitbook-link">Published using GitBook</a>
        </li>
        
    </ul>
</div>

    <div class="book-body">
        <div class="body-inner">
            <div class="book-header">
    <!-- Actions Left -->
    <a href="#" class="btn pull-left toggle-summary" aria-label="Toggle summary"><i class="fa fa-align-justify"></i></a>
    <a href="#" class="btn pull-left toggle-search" aria-label="Toggle search"><i class="fa fa-search"></i></a>
    
    <div id="font-settings-wrapper" class="dropdown pull-left">
        <a href="#" class="btn toggle-dropdown" aria-label="Toggle font settings"><i class="fa fa-font"></i>
        </a>
        <div class="dropdown-menu font-settings">
    <div class="dropdown-caret">
        <span class="caret-outer"></span>
        <span class="caret-inner"></span>
    </div>

    <div class="buttons">
        <button type="button" id="reduce-font-size" class="button size-2">A</button>
        <button type="button" id="enlarge-font-size" class="button size-2">A</button>
    </div>

    <div class="buttons font-family-list">
        <button type="button" data-font="0" class="button">Serif</button>
        <button type="button" data-font="1" class="button">Sans</button>
    </div>

    <div class="buttons color-theme-list">
        <button type="button" id="color-theme-preview-0" class="button size-3" data-theme="0">White</button>
        <button type="button" id="color-theme-preview-1" class="button size-3" data-theme="1">Sepia</button>
        <button type="button" id="color-theme-preview-2" class="button size-3" data-theme="2">Night</button>
    </div>
</div>

    </div>

    <!-- Actions Right -->
    
    <div class="dropdown pull-right">
        <a href="#" class="btn toggle-dropdown" aria-label="Toggle share dropdown"><i class="fa fa-share-alt"></i>
        </a>
        <div class="dropdown-menu font-settings dropdown-left">
            <div class="dropdown-caret">
                <span class="caret-outer"></span>
                <span class="caret-inner"></span>
            </div>
            <div class="buttons">
                <button type="button" data-sharing="twitter" class="button">Twitter</button>
                <button type="button" data-sharing="google-plus" class="button">Google</button>
                <button type="button" data-sharing="facebook" class="button">Facebook</button>
                <button type="button" data-sharing="weibo" class="button">Weibo</button>
                <button type="button" data-sharing="instapaper" class="button">Instapaper</button>
            </div>
        </div>
    </div>
    

    
    <a href="#" target="_blank" class="btn pull-right google-plus-sharing-link sharing-link" data-sharing="google-plus" aria-label="Share on Google Plus"><i class="fa fa-google-plus"></i></a>
    
    
    <a href="#" target="_blank" class="btn pull-right facebook-sharing-link sharing-link" data-sharing="facebook" aria-label="Share on Facebook"><i class="fa fa-facebook"></i></a>
    
    
    <a href="#" target="_blank" class="btn pull-right twitter-sharing-link sharing-link" data-sharing="twitter" aria-label="Share on Twitter"><i class="fa fa-twitter"></i></a>
    
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../../" >机器学习</a>
    </h1>
</div>

            <div class="page-wrapper" tabindex="-1">
                <div class="page-inner">
                
                
                    <section class="normal" id="section-gitbook_8">
                    
                        <h2 id="----document-filtering">文档过滤 -- Document Filtering</h2>
<p>本章介绍如何依据内容对文档进行分类，文档分类是机器智能（machine intelligence）的一个应用。</p>
<p>例子：</p>
<ol>
<li>垃圾邮件过滤</li>
<li>将来自某一RSS订阅源的内容项目自动过滤到不同的分类中</li>
</ol>
<h3 id="----filtering-spam">过滤垃圾信息 -- Filtering Spam</h3>
<p>基于规则的分类器（rule-based classifier），使用时会有人事先设计好一组规则，用以指明某条信息是否属于垃圾信息。</p>
<p>存在的问题是</p>
<ol>
<li>垃圾信息制造者知道规则后，就可以绕开过滤器</li>
<li>是否被当作垃圾信息很大程度上因其所面对的读者和张贴位置的不同而不同。</li>
</ol>
<p>解决：程序在开始阶段逐渐收到更多消息之后，根据人们提供给它的有关哪些是垃圾邮件，哪些不是垃圾邮件的信息，不断地进行学习。通过这样的方式，我们可以分别为不同的用户、群组或网站建立起各自的应用实例和数据集，它们对垃圾信息的界定将逐步形成自己的观点。</p>
<h3 id="----documents-and-words">文档和单词 -- Documents and Words</h3>
<p>分类器需要用某些特征来对不同的内容项进行分类。所谓特征，是指任何可以用来判断内容中具备或缺失的东西。
在对文档进行分类时，内容即是文档，特征则是文档中的单词。单词作为特征时，其假设是：某些单词相对而言更有可能出现在垃圾信息中。</p>
<pre><code class="lang-python"><span class="hljs-comment"># docclass.py</span>
<span class="hljs-keyword">import</span> re
<span class="hljs-keyword">import</span> math

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getwords</span><span class="hljs-params">(doc)</span>:</span>
    splitter = re.compile(<span class="hljs-string">'\\W*'</span>)
    <span class="hljs-comment"># 根据非字母字符进行单词拆分</span>
    words = [s.lower() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> splitter.split(doc) <span class="hljs-keyword">if</span> len(s)&gt;<span class="hljs-number">2</span> <span class="hljs-keyword">and</span> len(s)&lt;<span class="hljs-number">20</span>]
    <span class="hljs-comment"># 只返回一组不重复的单词</span>
    <span class="hljs-keyword">return</span> {w:<span class="hljs-number">1</span> <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> words}
</code></pre>
<p>选择特征集时需要做大量的权衡，而且还要不断地进行调整</p>
<h3 id="----training-the-classifier">对分类器进行训练 -- Training the Classifier</h3>
<pre><code class="lang-python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">classifier</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, getfeatures, filename=None)</span>:</span>
        <span class="hljs-comment"># 统计特征/分类组合的数量</span>
        self.fc = {}
        <span class="hljs-comment"># 统计每个分类中的文档数量</span>
        self.cc = {}
        self.getfeatures = getfeatures

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">setdb</span><span class="hljs-params">(self, dbfile)</span>:</span>
        self.con = sqlite.connect(dbfile)
        self.con.execute(<span class="hljs-string">'create table if not exists fc(feature,category,count)'</span>)
        self.con.execute(<span class="hljs-string">'create table if not exists cc(category,count)'</span>)

    <span class="hljs-comment"># 类方法不会直接引用这些字典，因为这会有碍于将训练数据存入文件或数据库的潜在选择。加入下列辅助函数</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">incf</span><span class="hljs-params">(self, f, cat)</span>:</span>
        <span class="hljs-string">'''增加对特征/分类组合的计数值'''</span>
        <span class="hljs-comment">#self.fc.setdefault(f, {})</span>
        <span class="hljs-comment">#self.fc[f].setdefault(cat, 0)</span>
        <span class="hljs-comment">#self.fc[f][cat] += 1</span>
        count = self.fcount(f, cat)
        <span class="hljs-keyword">if</span> count == <span class="hljs-number">0</span>:
            self.con.execute(<span class="hljs-string">"insert into fc values ('%s','%s'1)"</span> % (f, cat))
        <span class="hljs-keyword">else</span>:
            self.con.execute(
                <span class="hljs-string">"update fc set count=%d where feature='%s' and category='%s'"</span> % (count+<span class="hljs-number">1</span>,f,cat))

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">incc</span><span class="hljs-params">(self, cat)</span>:</span>
        <span class="hljs-string">'''增加对某一分类的计数值'''</span>
        <span class="hljs-comment">#self.cc.setdefault(cat, 0)</span>
        <span class="hljs-comment">#sele.cc[cat] += 1</span>
        count=self.catcount(cat)
        <span class="hljs-keyword">if</span> count==<span class="hljs-number">0</span>:
            self.con.execute(<span class="hljs-string">"insert into cc values ('%s',1)"</span> % (cat))
        <span class="hljs-keyword">else</span>:
            self.con.execute(<span class="hljs-string">"update cc set count=%d where category='%s'"</span> 
                           % (count+<span class="hljs-number">1</span>,cat)) 

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fcount</span><span class="hljs-params">(self, f, cat)</span>:</span>
        <span class="hljs-string">'''某一特征出现于某一分类中的次数'''</span>
        <span class="hljs-comment">#if f in self.fc and cat in self.fc[f]:</span>
        <span class="hljs-comment">#    return float(self.fc[f][cat])</span>
        <span class="hljs-comment">#return 0.0</span>
        res=self.con.execute(
            <span class="hljs-string">'select count from fc where feature="%s" and category="%s"'</span>
            %(f,cat)).fetchone()
        <span class="hljs-keyword">if</span> res==<span class="hljs-keyword">None</span>: <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>
        <span class="hljs-keyword">else</span>: <span class="hljs-keyword">return</span> float(res[<span class="hljs-number">0</span>])

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">catcount</span><span class="hljs-params">(self, cat)</span>:</span>
        <span class="hljs-string">'''属于某一分类的内容项数量'''</span>
        <span class="hljs-comment">#if cat in self.cc:</span>
        <span class="hljs-comment">#    return float(self.cc[cat])</span>
        <span class="hljs-comment">#return 0</span>
        res=self.con.execute(<span class="hljs-string">'select count from cc where category="%s"'</span>
            %(cat)).fetchone()
        <span class="hljs-keyword">if</span> res==<span class="hljs-keyword">None</span>: <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>
        <span class="hljs-keyword">else</span>: <span class="hljs-keyword">return</span> float(res[<span class="hljs-number">0</span>])

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">totalcount</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-string">'''所有内容项的数量'''</span>
        <span class="hljs-comment">#return sum(self.cc.values())</span>
        res=self.con.execute(<span class="hljs-string">'select sum(count) from cc'</span>).fetchone();
        <span class="hljs-keyword">if</span> res==<span class="hljs-keyword">None</span>: <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>
        <span class="hljs-keyword">return</span> res[<span class="hljs-number">0</span>]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">categories</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-string">'''所有分类的列表'''</span>
        <span class="hljs-comment">#return self.cc.keys()</span>
        cur=self.con.execute(<span class="hljs-string">'select category from cc'</span>);
        <span class="hljs-keyword">return</span> [d[<span class="hljs-number">0</span>] <span class="hljs-keyword">for</span> d <span class="hljs-keyword">in</span> cur]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span><span class="hljs-params">(self, item, cat)</span>:</span>
        <span class="hljs-string">'''将内容拆分为彼此独立的各个特征。
        针对该分类为每个特征增加计数值。增加对该分类的总计数值'''</span>
        features = self.getfeatures(item)
        <span class="hljs-comment"># 针对该分类为每个特征增加计数值</span>
        <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> features:
            self.incf(f, cat)
        <span class="hljs-comment"># 增加针对该分类的计数值</span>
        self.incc(cat)
        self.con.commit()

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fprob</span><span class="hljs-params">(self, f, cat)</span>:</span>
        <span class="hljs-comment"># 给定分类的单词概率——分类cat中出现特征f的概率</span>
        <span class="hljs-keyword">if</span> self.catcount(cat) == <span class="hljs-number">0</span>: <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>
        <span class="hljs-comment"># 特征在分类中出现的总次数，除以分类中包含内容项的总数</span>
        <span class="hljs-keyword">return</span> self.fcount(f, cat)/self.catcount(cat)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">weightedprob</span><span class="hljs-params">(self, f, cat, prf, weight=<span class="hljs-number">1.0</span>, ap=<span class="hljs-number">0.5</span>)</span>:</span>
        <span class="hljs-string">'''在我们手头掌握的有关当前特征的信息极为有限时，我们还需要根据一个假设的概率来作出判断'''</span>
        <span class="hljs-comment"># 计算当前的概率值</span>
        basicprob = prf(f, cat)
        <span class="hljs-comment"># 统计特征在所有分类中出现的次数</span>
        totals = sum([self.fcount(f, c) <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> self.categories()])
        <span class="hljs-comment"># 计算加权平均</span>
        bp = ((weight*ap)+(totals*basicprob))/(weight+totals)
        <span class="hljs-keyword">return</span> bp

<span class="hljs-comment"># cl = classifier(getwords)</span>
<span class="hljs-comment"># cl.train('the quick brown fox jumps over the lazy dog', 'good')</span>
<span class="hljs-comment"># cl.train('make quick money in the online casino', 'bad')</span>
<span class="hljs-comment"># cl.fcount('quick', 'good')</span>
<span class="hljs-comment"># cl.fcount('quick', 'bad')</span>

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sampletrain</span><span class="hljs-params">(cl)</span>:</span>
    cl.train(<span class="hljs-string">'Nobody owns the water'</span>, <span class="hljs-string">'good'</span>)
    cl.train(<span class="hljs-string">'the quick rabbit jumps fences'</span>, <span class="hljs-string">'good'</span>)
    cl.train(<span class="hljs-string">'buy pharmaceuticals now'</span>, <span class="hljs-string">'bad'</span>)
    cl.train(<span class="hljs-string">'make quick money at the online casino'</span>, <span class="hljs-string">'bad'</span>)
    cl.train(<span class="hljs-string">'the quick brown fox jumps'</span>, <span class="hljs-string">'good'</span>)
</code></pre>
<h3 id="----calculating-probabilities">计算概率 -- Calculating Probabilities</h3>
<p>fprob：给定分类的单词概率——分类cat中出现特征f的概率
为条件概率，记为Pr(A|B)，在给定B的条件下A的概率
本例中，Pr(word|classification)
classifier.fprob(self, f, cat)</p>
<p>sampletrain(cl)
cl.fprob(&#39;quick&#39;, &#39;good&#39;)</p>
<h4 id="----starting-with-a-reasonable-guess">从一个合理的推测开始 -- Starting with a Reasonable Guess</h4>
<p>fprob方法针对目前为止见到过的特征与分类，给出了一个精确的结果。但它有一个小问题——只根据以往见过的信息，会令其在训练的初期阶段，对那些极少出现的单词变得异常敏感。</p>
<p>为解决上述问题，在我们手头掌握的有关当前特征的信息极为有限时，我们还需要根据一个假设的概率来作出判断。一个推荐的初始值是0.5.我们还要为假设的概率赋以多大的权重——权重为1代表假设概率的权重与一个单词相当。经过加权的概率值返回的是一个有getprobability与假设概率组成的加权平均。</p>
<pre><code class="lang-python">classifier.weightedprob(self, f, cat, prf, weight=<span class="hljs-number">1.0</span>, ap=<span class="hljs-number">0.5</span>)

sampletrain(cl)
cl.weightedprob(<span class="hljs-string">'money'</span>, <span class="hljs-string">'good'</span>, cl.fprob)
sampletrain(cl)
cl.weightedprob(<span class="hljs-string">'money'</span>, <span class="hljs-string">'good'</span>, cl.fprob)
</code></pre>
<h3 id="----a-naive-classifier">朴素分类器 -- A Naive Classifier</h3>
<p>将各个单词的概率进行组合，从而得出整篇文档属于该分类的概率。
本章将考查两种不同的分类方法。</p>
<p>朴素贝叶斯分类器：朴素指的是它假设将要被组合的各个概率是彼此独立的。即，一个单词在属于某个指定分类的文档中出现的概率，与其他单词出现于该分类的概率是不相关的。</p>
<p>事实上文章中的各个单词并不是独立的，这意味着我们无法采用朴素贝叶斯分类器所求得的结果实际用作一篇文档属于某个分类的概率。不过，我们还是可以对各个分类的计算结果进行比较，然后在看哪个分类的概率最大。在现实中，若不考虑假设的潜在缺陷，朴素贝叶斯分类器将被证明是一种非常有效的文档分类方法。</p>
<h4 id="----probability-of-a-whole-document">整篇文档的概率 -- Probability of a Whole Document</h4>
<p>假设概率的彼此独立性
Pr(Document|Category) = Pr(w1|Category) * Pr(w2|Category)...</p>
<pre><code class="lang-python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">naivebayes</span><span class="hljs-params">(classifier)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, getfeatures)</span>:</span>
        classifier.__init__(self, getfeatures)
        self.thresholds = {}

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">setthreshold</span><span class="hljs-params">(self, cat, t)</span>:</span>
        self.thresholds[cat] = t

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getthreshold</span><span class="hljs-params">(self, cat)</span>:</span>
        <span class="hljs-keyword">if</span> cat <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> self.thresholds: <span class="hljs-keyword">return</span> <span class="hljs-number">1.0</span>
        <span class="hljs-keyword">return</span> self.thresholds[cat]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">docprob</span><span class="hljs-params">(self, item, cat)</span>:</span>
        <span class="hljs-string">'''得到整篇文档的概率'''</span>
        features = self.getfeatures(item)

        <span class="hljs-comment"># 将所有特征的概率相乘</span>
        p = <span class="hljs-number">1</span>
        <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> features: p *= self.weightedprob(f, cat, self.fprob)
        <span class="hljs-keyword">return</span> p

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">prob</span><span class="hljs-params">(self, item, cat)</span>:</span>
        <span class="hljs-string">'''计算分类的概率 Pr(Category|Document)
        = Pr(Document|Category) * Pr(Category) / Pr(Document)
        '''</span>
        catprob = self.catcount(cat)/self.totalcount()
        docprob = self.docprob(item, cat)
        <span class="hljs-keyword">return</span> docprob * catprob

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">classify</span><span class="hljs-params">(self, item, default=None)</span>:</span>
        probs = {}
        <span class="hljs-comment"># 寻找概率最大的分类</span>
        max = <span class="hljs-number">0.0</span>
        <span class="hljs-keyword">for</span> cat <span class="hljs-keyword">in</span> self.categories():
            probs[cat] = self.prob(item, cat)
            <span class="hljs-keyword">if</span> probs[cat] &gt; max:
                max = probs[cat]
                best = cat

        <span class="hljs-comment"># 确保概率超出域值*次大概率值</span>
        <span class="hljs-keyword">for</span> cat <span class="hljs-keyword">in</span> probs:
            <span class="hljs-keyword">if</span> cat == best: <span class="hljs-keyword">continue</span>
            <span class="hljs-keyword">if</span> probs[cat] * self.getthreshold(best)&gt;probs[best]: <span class="hljs-keyword">return</span> default
        <span class="hljs-keyword">return</span> best
</code></pre>
<h4 id="----a-quick-introduction-to-bayes-theorem">贝叶斯定理简介 -- A Quick Introduction to Bayes Theorem</h4>
<p>贝叶斯定理是一种对条件概率进行调换求解（flipping around）的方法，通常写作：
Pr(A|B) = Pr(B|A) <em> Pr(A) / Pr(B)
在本例中，即为：
Pr(Category|Document) = Pr(Document|Category) </em> Pr(Category)/Pr(Document)
Pr(Document|Category) = Pr(w1|Category) * Pr(w2|Category)...
Pr(Category)是随机选择一篇文档属于该分类的概率，因此就是属于该分类的文档数除以文档的总数。</p>
<p>naivebayes.prob(self, item, cat)</p>
<pre><code class="lang-python">cl = naivebayes(getwords)
sampletrain(cl)
cl.prob(<span class="hljs-string">'quick rabbit'</span>, <span class="hljs-string">'good'</span>)
cl.prob(<span class="hljs-string">'quick rabbit'</span>, <span class="hljs-string">'bad'</span>)
</code></pre>
<h4 id="----choosing-a-category">选择分类 -- Choosing a Category</h4>
<p>构造朴素贝叶斯分类器的最后一个步骤是实际判定某个内容项所属的分类。
此处最简单的方法是计算被考查内容在每个不同分类中的概率，然后选择概率最大的分类。
在许多问题中无法将各个分类同等看待，如与将正常邮件归为垃圾邮件相比，偶尔收到几封垃圾邮件还是可以容忍的。在另一些应用中承认不知道答案，要好过判断答案就是概率值稍大一些的分类。</p>
<p>为解决这一问题，我们可以为每个分类定义一个最小阈值。
以垃圾邮件过滤为例，假如过滤到“bad”分类的阈值为3，则针对“bad”分类的概率就必须至少3倍于针对“good”分类的概率才行。假如针对“good”分类的阈值为1，则对于任何邮件，只要概率确实大于针对“bad“分类的概率，它就是属于”good“分类的。任何有可能属于”bad“分类，但概率并没有超过3倍以上的邮件，都将被划归到”未知“分类中。</p>
<pre><code class="lang-python"><span class="hljs-comment"># 阈值操作</span>
classifier.__init__(self, getfeatures)
classifier.setthreshold(self, cat, t)
classifier.getthreshold(self, cat)

<span class="hljs-comment"># 分类</span>
classifier.classify(self, item, default=<span class="hljs-keyword">None</span>)

cl = naivebayes(getwords)
sampletrain(cl)
cl.classify(<span class="hljs-string">'quick rabbit'</span>, default=<span class="hljs-string">'unknown'</span>)
cl.classify(<span class="hljs-string">'quick money'</span>, default=<span class="hljs-string">'unknown'</span>)
cl.setthreshold(<span class="hljs-string">'bad'</span>, <span class="hljs-number">3.0</span>)
cl.classify(<span class="hljs-string">'quick money'</span>, default=<span class="hljs-string">'unknown'</span>)
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>): sampletrain(cl)
cl.classify(<span class="hljs-string">'quick money'</span>, default=<span class="hljs-string">'unknown'</span>)
</code></pre>
<h3 id="----the-fisher-method">费舍尔方法 -- The Fisher Method</h3>
<p>以R.A.Fisher的名字命名的费舍尔方法，是朴素贝叶斯方法的一种替代方案，它可以给出非常精确的结果，尤其适合垃圾信息过滤。</p>
<p>与朴素贝叶斯过滤器利用特征概率来计算整篇文档的概率不同，费舍尔方法为文档中的每个特征都求得了分类的概率，然后又将这些概率组合起来，并判断其是否可能构成一个随机集合。尽管该方法更为复杂，但是因为它在分类选择临界值（cutoff）时允许更大的灵活性，所以还是值得一学的。</p>
<h4 id="----category-probabilities-for-features">针对特征的分类概率 -- Category Probabilities for Features</h4>
<p>cprob：给定单词的分类概率——特征f出现在cat中的概率
Pr(category|feature)
(具有指定特征的属于某分类的文档数)/(具有指定特征的文档总数)</p>
<p>为了进行归一化计算，函数将分别求得3个量</p>
<ul>
<li>属于某分类的概率 clf=Pr(feature|category)</li>
<li>属于所有分类的概率 freqsum = Pr(feature|category)之和</li>
<li>cprob = clf/(clf+nclf)</li>
</ul>
<pre><code class="lang-python"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">fisherclassifier</span><span class="hljs-params">(classifier)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self, getfeatures)</span>:</span>
        classifier.__init__(self, getfeatures)
        self.minimums = {}

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">setminimum</span><span class="hljs-params">(self, cat, min)</span>:</span>
        self.minimums[cat] = min

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">getminimun</span><span class="hljs-params">(self, cat)</span>:</span>
        <span class="hljs-keyword">if</span> cat <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> self.minimums: <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>
        <span class="hljs-keyword">return</span> self.minimums[cat]

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">cprob</span><span class="hljs-params">(self, f, cat)</span>:</span>
        <span class="hljs-string">'''特征f出现在cat中的概率'''</span>
        <span class="hljs-comment"># 特征在该分类中出现的频率</span>
        clf = self.fprob(f, cat)
        <span class="hljs-keyword">if</span> clf == <span class="hljs-number">0</span>: <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>
        <span class="hljs-comment"># 特征在所有分类中出现的频率</span>
        freqsum = sum([self.fprob(f,c) <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> self.categories()])
        <span class="hljs-comment"># 概率等于特征在该分类中出现的频率除以总体频率</span>
        p = clf/(freqsum)

        <span class="hljs-keyword">return</span> p

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fisherprob</span><span class="hljs-params">(self, item, cat)</span>:</span>
        <span class="hljs-comment"># 将所有概率值相乘</span>
        p = <span class="hljs-number">1</span>
        features = self.getfeatures(item)
        <span class="hljs-keyword">for</span> f <span class="hljs-keyword">in</span> features:
            p *= (self.weightedprob(f, cat, self.cprob))
        <span class="hljs-comment"># 取自然对数，并乘以-2</span>
        fscore = -<span class="hljs-number">2</span> * math.log(p)
        <span class="hljs-comment"># 利用倒置对数卡方函数求得概率</span>
        <span class="hljs-keyword">return</span> self.invchi2(fscore, len(features)*<span class="hljs-number">2</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">invchi2</span><span class="hljs-params">(self, chi, df)</span>:</span>
        m = chi / <span class="hljs-number">2.0</span>
        sum = term = math.exp(-m)
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">1</span>, df//<span class="hljs-number">2</span>):
            term *= m / i
            sum += term
        <span class="hljs-keyword">return</span> min(sum, <span class="hljs-number">1.0</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">classify</span><span class="hljs-params">(self, item, default=None)</span>:</span>
        <span class="hljs-comment"># 循环遍历并寻找最佳结果</span>
        best = default
        max = <span class="hljs-number">0.0</span>
        <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> self.categories():
            p = self.fisherprob(item, c)
            <span class="hljs-comment"># 确保其超过下限值</span>
            <span class="hljs-keyword">if</span> p &gt; self.getminimun(c) <span class="hljs-keyword">and</span> p &gt; max:
                best = c
                max = p
        <span class="hljs-keyword">return</span> best

<span class="hljs-comment"># cl = fisherclassifier(getwords)</span>
<span class="hljs-comment"># sampletrain(cl)</span>
<span class="hljs-comment"># cl.cprob('quick', 'good')</span>
<span class="hljs-comment"># cl.cprob('money', 'bad')</span>
</code></pre>
<p>对于因为算法接触单词的次数太少，所以它有可能会对概率值估计过高。因此可以对概率进行加权处理</p>
<p>cl.weightedprob(&#39;money&#39;, &#39;bad&#39;, cl.cprob)</p>
<h4 id="----combining-the-probabilities">将各概率值组合起来 -- Combining the Probabilities</h4>
<p>费舍尔方法返回的结果是对概率的一种更好的估计，这对于结果报告或临界值判断而言是非常有价值的。</p>
<p>费舍尔方法的计算过程是将所有概率相乘起来，然后取自然对数，在将结果乘以-2</p>
<pre><code class="lang-python">fisherclassifier.fisherprob(self, item, cat)

cl = fisherclassifier(getwords)
sampletrain(cl)
cl.cprob(<span class="hljs-string">'quick'</span>, <span class="hljs-string">'good'</span>)
cl.fisherprob(<span class="hljs-string">'quick rabbit'</span>, <span class="hljs-string">'good'</span>)
cl.fisherprob(<span class="hljs-string">'quick rabbit'</span>, <span class="hljs-string">'bad'</span>)
</code></pre>
<h4 id="----classifying-items">对内容项进行分类 -- Classifying Items</h4>
<p>我们可以利用fisherprob的返回值来决定如何进行分类。不像贝叶斯过滤器那样需要乘以阈值，此处我们可以为每个分类指定下限。
在垃圾信息过滤器中，我们可以将“bad”分类的下限值设得很高，如0.6，将“good”分类的下限值设置得很低，比如0.2.任何针对“good”分类的分值低于0.2，针对“bad”分类的分值低于0.6的邮件，将被划归到“未知”分类中。</p>
<pre><code class="lang-python">fisherclassifier.__init__(self, getfeatures)
fisherclassifier.setminimum(self, cat, min)
fisherclassifier.getminimun(self, cat)
fisherclassifier.classify(self, item, default=<span class="hljs-keyword">None</span>)

sampletrain(cl)
cl.classify(<span class="hljs-string">'quick rabbit'</span>)
cl.classify(<span class="hljs-string">'quick money'</span>)
cl.setminimum(<span class="hljs-string">'bad'</span>, <span class="hljs-number">0.8</span>)
cl.classify(<span class="hljs-string">'quick money'</span>)
cl.setminimum(<span class="hljs-string">'good'</span>, <span class="hljs-number">0.4</span>)
cl.classify(<span class="hljs-string">'quick money'</span>)
</code></pre>
<h3 id="----persisting-the-trained-classifiers">将经过训练的分类器持久化 -- Persisting the Trained Classifiers</h3>
<h4 id="using-sqlite">Using SQLite</h4>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> sqlite3 <span class="hljs-keyword">as</span> sqlite

<span class="hljs-comment"># 需要修改的函数</span>
classifier.setdb(self, dbfile)
classifier.incf(self, f, cat)
classifier.fcount(self, f, cat)
classifier.incc(self, cat)
classifier.catcount(self, cat)
classifier.categories(self)
classifier.totalcount(self)

cl = fisherclassifier(getwords)
cl.setdb(<span class="hljs-string">'test1.db'</span>)
sampletrain(cl)
cl2 = naivebayes(getwords)
cl2.setdb(<span class="hljs-string">'test1.db'</span>)
cl2.classify(<span class="hljs-string">'quick money'</span>)
</code></pre>
<h3 id="----filtering-blog-feeds">过滤博客订阅源 -- Filtering Blog Feeds</h3>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> feedparser
<span class="hljs-keyword">import</span> re

<span class="hljs-comment"># Takes a filename of URL of a blog feed and classifies the entries</span>
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">read</span><span class="hljs-params">(feed,classifier)</span>:</span>
  <span class="hljs-comment"># Get feed entries and loop over them</span>
  f=feedparser.parse(feed)
  <span class="hljs-keyword">for</span> entry <span class="hljs-keyword">in</span> f[<span class="hljs-string">'entries'</span>]:
    <span class="hljs-keyword">print</span>
    <span class="hljs-keyword">print</span> <span class="hljs-string">'-----'</span>
    <span class="hljs-comment"># Print the contents of the entry</span>
    <span class="hljs-keyword">print</span> <span class="hljs-string">'Title:     '</span>+entry[<span class="hljs-string">'title'</span>].encode(<span class="hljs-string">'utf-8'</span>)
    <span class="hljs-keyword">print</span> <span class="hljs-string">'Publisher: '</span>+entry[<span class="hljs-string">'publisher'</span>].encode(<span class="hljs-string">'utf-8'</span>)
    <span class="hljs-keyword">print</span>
    <span class="hljs-keyword">print</span> entry[<span class="hljs-string">'summary'</span>].encode(<span class="hljs-string">'utf-8'</span>)


    <span class="hljs-comment"># Combine all the text to create one item for the classifier</span>
    fulltext=<span class="hljs-string">'%s\n%s\n%s'</span> % (entry[<span class="hljs-string">'title'</span>],entry[<span class="hljs-string">'publisher'</span>],entry[<span class="hljs-string">'summary'</span>])

    <span class="hljs-comment"># Print the best guess at the current category</span>
    <span class="hljs-keyword">print</span> <span class="hljs-string">'Guess: '</span>+str(classifier.classify(entry))

    <span class="hljs-comment"># Ask the user to specify the correct category and train on that</span>
    cl=raw_input(<span class="hljs-string">'Enter category: '</span>)
    classifier.train(entry,cl)


<span class="hljs-comment"># cl = fisherclassifier(getwords)</span>
<span class="hljs-comment"># cl.setdb('python_feed.db')</span>
<span class="hljs-comment"># read('python_search.xml', cl)</span>

<span class="hljs-comment"># cl.cprob('python', 'prog')</span>
<span class="hljs-comment"># cl.cprob('python', 'snake')</span>
<span class="hljs-comment"># cl.cprob('python', 'monty')</span>
<span class="hljs-comment"># cl.cprob('eric', 'monty')</span>
<span class="hljs-comment"># cl.fprob('eric', 'monty')</span>
</code></pre>
<h3 id="----improving-feature-detection">对特征检测的改进 -- Improving Feature Detection</h3>
<p>几种不同的方法可以对其加以改进</p>
<ul>
<li>不真正区分大写和小写的单词，而是将”含有许多大写单词“这样的现象作为一种特征</li>
<li>除了单个单词外，还可以使用词组</li>
<li>捕获更多的元信息，如：是谁发送的电子邮件，或者一篇博客被提交到了哪个分类下，可以将这样的信息标示为元信息</li>
<li>保持URL和数字原封不动，不对其进行拆分</li>
</ul>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">entryfeatures</span><span class="hljs-params">(entry)</span>:</span>
  splitter=re.compile(<span class="hljs-string">'\\W*'</span>)
  f={}

  <span class="hljs-comment"># Extract the title words and annotate</span>
  titlewords=[s.lower() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> splitter.split(entry[<span class="hljs-string">'title'</span>]) 
          <span class="hljs-keyword">if</span> len(s)&gt;<span class="hljs-number">2</span> <span class="hljs-keyword">and</span> len(s)&lt;<span class="hljs-number">20</span>]
  <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> titlewords: f[<span class="hljs-string">'Title:'</span>+w]=<span class="hljs-number">1</span>

  <span class="hljs-comment"># Extract the summary words</span>
  summarywords=[s.lower() <span class="hljs-keyword">for</span> s <span class="hljs-keyword">in</span> splitter.split(entry[<span class="hljs-string">'summary'</span>]) 
          <span class="hljs-keyword">if</span> len(s)&gt;<span class="hljs-number">2</span> <span class="hljs-keyword">and</span> len(s)&lt;<span class="hljs-number">20</span>]

  <span class="hljs-comment"># Count uppercase words</span>
  uc=<span class="hljs-number">0</span>
  <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(summarywords)):
    w=summarywords[i]
    f[w]=<span class="hljs-number">1</span>
    <span class="hljs-keyword">if</span> w.isupper(): uc+=<span class="hljs-number">1</span>

    <span class="hljs-comment"># Get word pairs in summary as features</span>
    <span class="hljs-keyword">if</span> i&lt;len(summarywords)-<span class="hljs-number">1</span>:
      twowords=<span class="hljs-string">' '</span>.join(summarywords[i:i+<span class="hljs-number">1</span>])
      f[twowords]=<span class="hljs-number">1</span>

  <span class="hljs-comment"># Keep creator and publisher whole</span>
  f[<span class="hljs-string">'Publisher:'</span>+entry[<span class="hljs-string">'publisher'</span>]]=<span class="hljs-number">1</span>

  <span class="hljs-comment"># UPPERCASE is a virtual word flagging too much shouting  </span>
  <span class="hljs-keyword">if</span> float(uc)/len(summarywords)&gt;<span class="hljs-number">0.3</span>: f[<span class="hljs-string">'UPPERCASE'</span>]=<span class="hljs-number">1</span>

  <span class="hljs-keyword">return</span> f

cl = fisherclassifier(entryfeatures)
cl.setdb(<span class="hljs-string">'python_feed.db'</span>)
read(<span class="hljs-string">'python_search.xml'</span>, cl)
</code></pre>
<h3 id="using-akismet">Using Akismet</h3>
<p>??</p>
<h3 id="----alternative-methods">替代方法 -- Alternative Methods</h3>
<p>本章介绍的两个分类器都是监督型学习方法(supervised learning methods)的例子
第4章中的人工神经网络是另一个监督型学习的例子。通过将特征作为输入，并令输出代表每一种可能的分类，我们也可以将神经网络用于本章中的相同问题。
第9章中介绍的支持向量机(support vector machines)，也可以用于解决本章的问题</p>
<p>贝叶斯分类器被常用于文档分类的原因是，与其他方法相比它所要求的计算资源更少。
相对与神经网络的复杂性导致了其在理解上的困难，我们可以清楚地看到单词的概率，以及它们对最终分值的实际贡献有多大，而对于网络中两个神经元之间的连接强度而言，则并不存在同样简单的解释</p>
<p>另一方面，神经网络和支持向量机有一个很大的优势：它们可以捕捉到输入特征之间更为复杂的关系。神经网络中，某个特征的概率可能会依据其他特征的存在或缺失而改变。也许你正在试图阻止赌博的垃圾信息，但是有对跑马很感兴趣，在这种情况下，只有电子邮件中的其他地方没有出现单词&#39;horse&#39;时，单词&#39;casino&#39;才被认为&#39;bad&#39;的。朴素贝叶斯分类器无法捕获这样的相互依赖性，而神经网络却是可以的。</p>
<h3 id="exercises">Exercises</h3>
<ol>
<li><strong>改变假设概率</strong> 请修改classifier类，使其能够支持对不同假设概率。修改init方法，使其能够接受其他分类器作为参数，并从一个更合理的假设概率推测值(而不是0.5)开始。</li>
<li><strong>计算 Pr(Document)</strong> 在朴素贝叶斯分类器中，Pr(Document)的计算被略过了，因为它对于比较概率值而言并不是必需的。在特征彼此独立的前提下，事实上利用Pr(Document)来计算整体概率值是可行的。应该如何计算Pr(Document)呢？
= Pr(w1) * Pr(w2) ...</li>
<li><strong>POP-3 电子邮件过滤器</strong> Python有一个用于下载电子邮件的库，叫做poplib，请编写一段脚本，从服务器下载电子邮件，并尝试对其进行分类。一封电子邮件包含有哪些不同的属性？你将如何利用这些属性来构建特征提取函数呢？</li>
<li><strong>任意长度的短语</strong> 本章为你示范了提取词组和单个单词的方法。请修改代码令特征提取过程变得可配置，使其能够一次提取出一组拥有指定数量的单词，并将之作为一个独立特征。</li>
<li><strong>保留IP地址</strong> IP地址、电话号码，以及其他数字信息可能有助于对垃圾信息的识别。请修改特征提取函数，使其将这些信息作为特征加以返回（IP地址中包含有句号，但是你依然须要剔除句子间的句号）。</li>
<li><strong>其他虚拟特征</strong> 有许多像UPPERCASE那样的虚拟特征，这些特征可能对文档分类很有帮助。篇幅过长的文档或长单词占据又是的情况也有可能是一种线索。请将这些情况也作为特征。你还能想到其他情况吗？</li>
<li><strong>神经网络分类器</strong> 请修改第4章中的神经网络，利用它对文档进行分类。如何对神经网络的输出结果进行比较？编写一个程序对文档进行分类，并对其进行上千次的训练。记录每一种算法执行所需的时间。如何对这些算法做出对比呢？<blockquote>
<p>输入层：文档特征（单词，作者等），隐含层：特征集合，输出层：分类类别</p>
</blockquote>
</li>
</ol>

                    
                    </section>
                
                
                </div>
            </div>
        </div>

        
        <a href="../../PCI/cap5/cap5.html" class="navigation navigation-prev " aria-label="Previous page: 优化"><i class="fa fa-angle-left"></i></a>
        
        
        <a href="../../PCI/cap7/cap7.html" class="navigation navigation-next " aria-label="Next page: 决策树建模"><i class="fa fa-angle-right"></i></a>
        
    </div>
</div>

        
<script src="../../gitbook/app.js"></script>

    
    <script src="https://cdn.mathjax.org/mathjax/2.4-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    

    
    <script src="../../gitbook/plugins/gitbook-plugin-mathjax/plugin.js"></script>
    

<script>
require(["gitbook"], function(gitbook) {
    var config = {"fontSettings":{"theme":null,"family":"sans","size":2}};
    gitbook.start(config);
});
</script>

        
    </body>
    
</html>
